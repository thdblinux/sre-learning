## O que iremos ver hoje

Durante o dia de hoje iremos aprender sobre todas as possibilidades que temos com a utiliza√ß√£o do` Prometheus + Kubernetes`!
Hoje √© dia de conhecer o sensacional` kube-prometheus`, projeto esse criado pelos mesmos criadores do `Prometheus Operator`, que nos permite monitorar o nosso cluster de Kubernetes de forma simples e eficiente. Al√©m disso, iremos aprender como utilizar o `Prometheus Adapter` para que possamos utilizar o nosso querido e lindo Prometheus como fonte de dados para o `Horizontal Pod Autoscaler`, ou seja, iremos aprender como utilizar o nosso querido e lindo Prometheus para escalar nossos pods de forma autom√°tica!
E ainda de quebra voc√™ vai aprender como instalar o Kubernetes, mais do que isso, voc√™ vai aprender como instalar um cluster EKS! Sim, voc√™ vai aprender como instalar um cluster `EKS`, o cluster de Kubernetes da` AWS`, atrav√©s da ferramenta eksctl, que √© uma ferramenta de linha de comando que nos permite instalar um cluster `EKS` em minutos!

**O que √© o kube-prometheus?**

O kube-prometheus √© um conjunto de manifestos do Kubernetes que nos permite ter o `Prometheus Operator`, `Grafana`,` AlertManager`, `Node Exporter`, `Kube-State-Metrics`, `Prometheus-Adapter` instalados e configurados de forma tranquila e com alta disponibilidade. Al√©m disso, ele nos permite ter uma vis√£o completa do nosso cluster de Kubernetes. Ele nos permite monitorar todos os componentes do nosso cluster de Kubernetes, como por exemplo:` kube-scheduler`, k`ube-controller-manager`, `kubelet, kube-proxy`, etc.

**Instalando o nosso cluster Kubernetes**
Como dissemos, para esse nosso exemplo iremos utilizar o cluster de Kubernetes da` AWS`, o EKS. Para instalar o nosso cluster EKS, iremos utilizar a ferramenta `eksctl`, portanto precisamos instal√°-la em nossa m√°quina. Para instalar a ferramenta, basta executar o seguinte comando:

```sh
curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
```
```sh
sudo mv /tmp/eksctl /usr/local/bin
```
Precisamos ter o CLI da` aws` instalado em nossa m√°quina, para isso, basta executar o seguinte comando:

```sh
curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
```

```sh
unzip awscliv2.zip
```

```sh
sudo ./aws/install
```
Pronto, agora voc√™ j√° tem o eksctl e o aws instalados em sua m√°quina.

Para que possamos criar tudo o que precisamos na AWS, √© importante que voc√™ tenha uma conta na AWS, e que tenha as credenciais de acesso configuradas em sua m√°quina. Para configurar as credenciais de acesso, basta executar o seguinte comando:
```sh
aws configure
```
O comando acima ir√° solicitar que voc√™ informe a sua` AWS Access Key ID`, a sua `AWS Secret Access Key`, a sua Default region name, e o seu Default output format. Para saber mais sobre como configurar as credenciais de acesso, basta acessar a documenta√ß√£o oficial da AWS.

No comando acima estamos baixando o bin√°rio do eksctl compactado e descompactando ele na pasta /tmp, e depois movendo o bin√°rio para a pasta` /usr/local/bin`.

Lembrando que estou instando em uma m√°quina Linux, caso que esteja utilizando uma m√°quina Mac ou Windows, basta acessar a p√°gina de releases do projeto e baixar a vers√£o adequada para o seu sistema operacional.

E enquanto voc√™ faz a instala√ß√£o, vale a pena mencionar que o `eksctl` √© uma ferramenta criada pela `WeaveWorks`, empresa que criou o `Flux`, que √© um projeto de `GitOps` para `Kubernetes`, al√©m de ter o Weavenet, que √© um `CNI` para `Kubernetes`, e o `Weave Scope`, que √© uma ferramenta de visualiza√ß√£o de clusters de Kubernetes e muito mais, recomendo que voc√™s d√™em uma olhada nos projetos, √© sensacional!

Bem, agora voc√™ j√° tem o eksctl instalado em sua m√°quina, ent√£o vamos criar o nosso `cluster EKS`! Para isso, basta executar o seguinte comando:

```sh
eksctl create cluster --name=eks-cluster --version=1.24 --region=us-east-1 --nodegroup-name=eks-cluster-nodegroup --node-type=t3.medium --nodes=2 --nodes-min=1 --nodes-max=3 --managed
```

O comando acima ir√° criar um cluster EKS com o nome eks-cluster, na regi√£o us-east-1, com 2 n√≥s do tipo t3.medium, e com um m√≠nimo de 1 n√≥ e um m√°ximo de 3 n√≥s. Al√©m disso, o comando acima ir√° criar um nodegroup chamado eks-cluster-nodegroup. O eksctl ir√° cuidar de toda a infraestrutura necess√°ria para o funcionamento do nosso cluster EKS. A vers√£o do Kubernetes que ser√° instalada no nosso cluster ser√° a 1.24.

Ap√≥s a cria√ß√£o do nosso cluster EKS, precisamos instalar o kubectl em nossa m√°quina. Para instalar o kubectl, basta executar o seguinte comando:


```sh
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
```
```sh
chmod +x ./kubectl
```
```sh
sudo mv ./kubectl /usr/local/bin/kubectl
```
O comando acima ir√° baixar o bin√°rio do kubectl e o colocar na pasta `/usr/local/bin`, e dar permiss√£o de execu√ß√£o para o bin√°rio.

Agora que j√° temos o kubectl instalado em nossa m√°quina, precisamos configurar o kubectl para utilizar o nosso cluster EKS. Para isso, basta executar o seguinte comando:

```sh
aws eks --region us-east-1 update-kubeconfig --name eks-cluster
```
Aonde us-east-1 √© a regi√£o do nosso cluster EKS, e eks-cluster √© o nome do nosso cluster EKS. Esse comando √© necess√°rio para que o kubectl saiba qual cluster ele deve utilizar, ele ir√° pegar as credenciais do nosso cluster EKS e armazenar no arquivo` ~/.kube/config.`

LEMBRE-SE: Voc√™ n√£o precisa ter o Kubernetes rodando no EKS, fique a vontade para escolher onde preferir para seguir o treinamento.

Vamos ver se o kubectl est√° funcionando corretamente? Para isso, basta executar o seguinte comando:
```sh
kubectl get nodes
```
Se tudo estiver funcionando corretamente, voc√™ dever√° ver uma lista com os n√≥s do seu cluster EKS. üòÑ

Antes de seguirmos em frente, vamos conhecer algums comandos do eksctl, para que possamos gerenciar o nosso cluster EKS. Para listar os clusters EKS que temos em nossa conta, basta executar o seguinte comando:
```sh
eksctl get cluster -A
```
O parametro -A √© para listar os clusters EKS de todas as regi√µes. Para listar os clusters EKS de uma regi√£o espec√≠fica, basta executar o seguinte comando:

```sh
eksctl get cluster -r us-east-1
```
Para aumentar o n√∫mero de n√≥s do nosso cluster EKS, basta executar o seguinte comando:
```sh
eksctl scale nodegroup --cluster=eks-cluster --nodes=3 --nodes-min=1 --nodes-max=3 --name=eks-cluster-nodegroup -r us-east-1
```
Para diminuir o n√∫mero de n√≥s do nosso cluster EKS, basta executar o seguinte comando:
```sh
eksctl scale nodegroup --cluster=eks-cluster --nodes=1 --nodes-min=1 --nodes-max=3 --name=eks-cluster-nodegroup -r us-east-1
```
Para deletar o nosso cluster EKS, basta executar o seguinte comando:
```sh
eksctl delete cluster --name=eks-cluster -r us-east-1
```
Mas n√£o delete o nosso cluster EKS, vamos utilizar ele para os pr√≥ximos passos! hahahah

Instalando o Kube-Prometheus
Agora que j√° temos o nosso cluster EKS criado, vamos instalar o Kube-Prometheus. Para isso, basta executar o seguinte comando:
```sh
git clone https://github.com/prometheus-operator/kube-prometheus
```
```sh
cd kube-prometheus
```
```sh
kubectl create -f manifests/setup
```
Com o comando acima n√≥s estamos clonando o reposit√≥rio oficial do projeto, e aplicando os manifests necess√°rios para a instala√ß√£o do Kube-Prometheus. Ap√≥s a execu√ß√£o do comando acima, voc√™ dever√° ver uma mensagem parecida com a seguinte:

```sh
customresourcedefinition.apiextensions.k8s.io/alertmanagerconfigs.monitoring.coreos.com created
customresourcedefinition.apiextensions.k8s.io/alertmanagers.monitoring.coreos.com created
customresourcedefinition.apiextensions.k8s.io/podmonitors.monitoring.coreos.com created
customresourcedefinition.apiextensions.k8s.io/probes.monitoring.coreos.com created
customresourcedefinition.apiextensions.k8s.io/prometheuses.monitoring.coreos.com created
customresourcedefinition.apiextensions.k8s.io/prometheusrules.monitoring.coreos.com created
customresourcedefinition.apiextensions.k8s.io/servicemonitors.monitoring.coreos.com created
customresourcedefinition.apiextensions.k8s.io/thanosrulers.monitoring.coreos.com created
namespace/monitoring created
```
Basicamente o que fizemos foi a instala√ß√£o de alguns` CRDs (Custom Resource Definitions)` que s√£o como extens√µes do Kubernetes, e que s√£o utilizados pelo `Kube-Prometheu`s e com isso o Kubernetes ir√° reconhecer esses novos recursos, como por exemplo o PrometheusRule e o ServiceMonitor que irei falar mais a frente.

O processo de instala√ß√£o dos CRDs pode demorar alguns minutos, ent√£o vamos aguardar a instala√ß√£o terminar. üòÑ

Para verificar se a instala√ß√£o dos CRDs foi conclu√≠da, o comando abaixo dever√° funcionar,se ainda n√£o funcionar, aguarde alguns minutos e tente novamente.
```sh
kubectl get servicemonitors -A
```
Ap√≥s a instala√ß√£o dos` CRDs,` vamos instalar o Prometheus e o `Alertmanager`. Para isso, basta executar o seguinte comando:
```sh
kubectl apply -f manifests/
```
Com o comando acima n√≥s estamos aplicando os manifests necess√°rios para a instala√ß√£o do Prometheus e do` Alertmanager`. Ap√≥s a execu√ß√£o do comando acima, voc√™ dever√° ver uma mensagem parecida com a seguinte:

```sh
alertmanager.monitoring.coreos.com/main created
networkpolicy.networking.k8s.io/alertmanager-main created
poddisruptionbudget.policy/alertmanager-main created
prometheusrule.monitoring.coreos.com/alertmanager-main-rules created
secret/alertmanager-main created
service/alertmanager-main created
serviceaccount/alertmanager-main created
servicemonitor.monitoring.coreos.com/alertmanager-main created
clusterrole.rbac.authorization.k8s.io/blackbox-exporter created
clusterrolebinding.rbac.authorization.k8s.io/blackbox-exporter created
configmap/blackbox-exporter-configuration created
deployment.apps/blackbox-exporter created
networkpolicy.networking.k8s.io/blackbox-exporter created
service/blackbox-exporter created
serviceaccount/blackbox-exporter created
servicemonitor.monitoring.coreos.com/blackbox-exporter created
secret/grafana-config created
secret/grafana-datasources created
configmap/grafana-dashboard-alertmanager-overview created
configmap/grafana-dashboard-apiserver created
configmap/grafana-dashboard-cluster-total created
configmap/grafana-dashboard-controller-manager created
configmap/grafana-dashboard-grafana-overview created
configmap/grafana-dashboard-k8s-resources-cluster created
configmap/grafana-dashboard-k8s-resources-namespace created
configmap/grafana-dashboard-k8s-resources-node created
configmap/grafana-dashboard-k8s-resources-pod created
configmap/grafana-dashboard-k8s-resources-workload created
configmap/grafana-dashboard-k8s-resources-workloads-namespace created
configmap/grafana-dashboard-kubelet created
configmap/grafana-dashboard-namespace-by-pod created
configmap/grafana-dashboard-namespace-by-workload created
configmap/grafana-dashboard-node-cluster-rsrc-use created
configmap/grafana-dashboard-node-rsrc-use created
configmap/grafana-dashboard-nodes-darwin created
configmap/grafana-dashboard-nodes created
configmap/grafana-dashboard-persistentvolumesusage created
configmap/grafana-dashboard-pod-total created
configmap/grafana-dashboard-prometheus-remote-write created
configmap/grafana-dashboard-prometheus created
configmap/grafana-dashboard-proxy created
configmap/grafana-dashboard-scheduler created
configmap/grafana-dashboard-workload-total created
configmap/grafana-dashboards created
deployment.apps/grafana created
networkpolicy.networking.k8s.io/grafana created
prometheusrule.monitoring.coreos.com/grafana-rules created
service/grafana created
serviceaccount/grafana created
servicemonitor.monitoring.coreos.com/grafana created
prometheusrule.monitoring.coreos.com/kube-prometheus-rules created
clusterrole.rbac.authorization.k8s.io/kube-state-metrics created
clusterrolebinding.rbac.authorization.k8s.io/kube-state-metrics created
deployment.apps/kube-state-metrics created
networkpolicy.networking.k8s.io/kube-state-metrics created
prometheusrule.monitoring.coreos.com/kube-state-metrics-rules created
service/kube-state-metrics created
serviceaccount/kube-state-metrics created
servicemonitor.monitoring.coreos.com/kube-state-metrics created
prometheusrule.monitoring.coreos.com/kubernetes-monitoring-rules created
servicemonitor.monitoring.coreos.com/kube-apiserver created
servicemonitor.monitoring.coreos.com/coredns created
servicemonitor.monitoring.coreos.com/kube-controller-manager created
servicemonitor.monitoring.coreos.com/kube-scheduler created
servicemonitor.monitoring.coreos.com/kubelet created
clusterrole.rbac.authorization.k8s.io/node-exporter created
clusterrolebinding.rbac.authorization.k8s.io/node-exporter created
daemonset.apps/node-exporter created
networkpolicy.networking.k8s.io/node-exporter created
prometheusrule.monitoring.coreos.com/node-exporter-rules created
service/node-exporter created
serviceaccount/node-exporter created
servicemonitor.monitoring.coreos.com/node-exporter created
clusterrole.rbac.authorization.k8s.io/prometheus-k8s created
clusterrolebinding.rbac.authorization.k8s.io/prometheus-k8s created
networkpolicy.networking.k8s.io/prometheus-k8s created
poddisruptionbudget.policy/prometheus-k8s created
prometheus.monitoring.coreos.com/k8s created
prometheusrule.monitoring.coreos.com/prometheus-k8s-prometheus-rules created
rolebinding.rbac.authorization.k8s.io/prometheus-k8s-config created
rolebinding.rbac.authorization.k8s.io/prometheus-k8s created
rolebinding.rbac.authorization.k8s.io/prometheus-k8s created
rolebinding.rbac.authorization.k8s.io/prometheus-k8s created
role.rbac.authorization.k8s.io/prometheus-k8s-config created
role.rbac.authorization.k8s.io/prometheus-k8s created
role.rbac.authorization.k8s.io/prometheus-k8s created
role.rbac.authorization.k8s.io/prometheus-k8s created
service/prometheus-k8s created
serviceaccount/prometheus-k8s created
servicemonitor.monitoring.coreos.com/prometheus-k8s created
apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created
clusterrole.rbac.authorization.k8s.io/prometheus-adapter created
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created
clusterrolebinding.rbac.authorization.k8s.io/prometheus-adapter created
clusterrolebinding.rbac.authorization.k8s.io/resource-metrics:system:auth-delegator created
clusterrole.rbac.authorization.k8s.io/resource-metrics-server-resources created
configmap/adapter-config created
deployment.apps/prometheus-adapter created
networkpolicy.networking.k8s.io/prometheus-adapter created
poddisruptionbudget.policy/prometheus-adapter created
rolebinding.rbac.authorization.k8s.io/resource-metrics-auth-reader created
service/prometheus-adapter created
serviceaccount/prometheus-adapter created
servicemonitor.monitoring.coreos.com/prometheus-adapter created
clusterrole.rbac.authorization.k8s.io/prometheus-operator created
clusterrolebinding.rbac.authorization.k8s.io/prometheus-operator created
deployment.apps/prometheus-operator created
networkpolicy.networking.k8s.io/prometheus-operator created
prometheusrule.monitoring.coreos.com/prometheus-operator-rules created
service/prometheus-operator created
serviceaccount/prometheus-operator created
servicemonitor.monitoring.coreos.com/prometheus-operator created
```
Com isso fizemos a instala√ß√£o da Stack do nosso `Kube-Prometheus`, que √© composta pelo` Prometheus,` pelo` Alertmanager`, `Blackbox Exporter` e `Grafana`. üòÑ
Perceba que ele j√° est√° configurando um monte de outras coisas como os `ConfigMaps`, `Secrets,` `ServiceAccounts`, etc.

Para verificar se a instala√ß√£o foi conclu√≠da, basta executar o seguinte comando:
```sh
kubectl get pods -n monitoring
```
O resultado esperado √© o seguinte:
```sh
NAME                                  READY   STATUS    RESTARTS   AGE
alertmanager-main-0                   2/2     Running   0          57s
alertmanager-main-1                   2/2     Running   0          57s
alertmanager-main-2                   2/2     Running   0          57s
blackbox-exporter-cbb9c96b-t8z68      3/3     Running   0          94s
grafana-589787799d-pxsts              1/1     Running   0          80s
kube-state-metrics-557d857c5d-kt8dd   3/3     Running   0          78s
node-exporter-2n6sz                   2/2     Running   0          74s
node-exporter-mwq6b                   2/2     Running   0          74s
prometheus-adapter-758645c65b-54c7g   1/1     Running   0          64s
prometheus-adapter-758645c65b-cmjrv   1/1     Running   0          64s
prometheus-k8s-0                      2/2     Running   0          57s
prometheus-k8s-1                      2/2     Running   0          57s
prometheus-operator-c766b9756-vndp9   2/2     Running   0          63s
```
Pronto, j√° temos o Prometheus,` Alertmanager`,` Blackbox Exporter`,` Node Exporter` e `Grafana` instalados. üòÑ
Nesse meu cluster, eu estou com dois nodes, por isso temos dois pods do Node Exporter e dois pods do Prometheus chamados de` prometheus-k8s-0` e `prometheus-k8s-1`.

Agora que j√° temos o nosso` Kube-Prometheus` instalado, vamos acessar o nosso` Grafana` e verificar se est√° tudo funcionando corretamente. Para isso, vamos utilizar o kubectl port-forward para acessar o Grafana localmente. Para isso, basta executar o seguinte comando:
```sh
kubectl port-forward -n monitoring svc/grafana 33000:3000
```
Agora que j√° temos o nosso Grafana rodando localmente, vamos acessar o nosso Grafana atrav√©s do navegador. Para isso, basta acessar a seguinte `URL: http://localhost:33000`

Para acessar o Grafana, vamos utilizar o usu√°rio admin e a senha admin, e j√° no primeiro login ele ir√° pedir para voc√™ alterar a senha. Voc√™ j√° conhece o Grafana, n√£o preciso mais apresenta-los, certo? üòÑ



O importante aqui √© ver a quantidade de `Dashboards` criados pelo` Kube-Prometheus`. üòÑ
Temos `Dashboards` que mostram detalhes do API Server e de diversos componentes do Kubernetes, como Node, Pod, Deployment, etc.



Tamb√©m temos `Dashboards` que mostram detalhes do nosso cluster EKS, como por exemplo o dashboard` Kubernetes / Compute Resources / Cluster`, que mostra detalhes de CPU e mem√≥ria utilizados por todos os n√≥s do nosso cluster EKS.



`Dashboards` que mostram detalhes do nosso cluster EKS, como por exemplo o dashboard `Kubernetes / Compute Resources / Namespace (Pods)`, que mostra detalhes de CPU e mem√≥ria utilizados por todos os pods de todos os namespaces do nosso cluster EKS.



Ainda temos Dashboards que mostram detalhes do nosso cluster EKS, como por exemplo o `dashboard Kubernetes / Compute Resources / Namespace (Workloads)`, que mostra detalhes de CPU e mem√≥ria utilizados por todos os deployments, statefulsets e daemonsets de todos os namespaces do nosso cluster EKS.



Tamb√©m temos Dashboards que mostram detalhes do nosso cluster EKS, como por exemplo o dashboard `Kubernetes / Compute Resources / Node`, que mostra detalhes de CPU e mem√≥ria utilizados por todos os n√≥s do nosso cluster EKS.



Tamb√©m temos Dashboards que mostram detalhes do nosso cluster EKS, como por exemplo o dashboard` Kubernetes / Compute Resources / Pod (Containers)`, que mostra detalhes de CPU e mem√≥ria utilizados por todos os containers de todos os pods do nosso cluster EKS.



Eu n√£o vou ficar aqui dando spoilers, vai l√° voc√™ e confere a quantidade enorme de Dashboards que o` Kube-Prometheus` j√° vem com ele. \o/


Um dos principais recursos que o` Kube-Prometheus` utiliza √© o` ServiceMonitor`. O ServiceMonitor √© um recurso do Prometheus Operator que permite que voc√™ configure o Prometheus para monitorar um servi√ßo. Para isso, voc√™ precisa criar um ServiceMonitor para cada servi√ßo que voc√™ deseja monitorar.

O Kube-Prometheus j√° vem com v√°rios ServiceMonitors configurados, como por exemplo o` ServiceMonitor` do `API Server`, do `Node Exporter`, do `Blackbox Exporter,` etc.

```sh
kubectl get servicemonitors -n monitoring
NAME                      AGE
alertmanager              17m
blackbox-exporter         17m
coredns                   17m
grafana                   17m
kube-apiserver            17m
kube-controller-manager   17m
kube-scheduler            17m
kube-state-metrics        17m
kubelet                   17m
node-exporter             17m
prometheus-adapter        17m
prometheus-k8s            17m
prometheus-operator       17m
```
Para ver o conte√∫do de um ServiceMonitor, basta executar o seguinte comando:
```sh
kubectl get servicemonitor prometheus-k8s -n monitoring -o yaml
```
Nesse caso estamos pegando o ServiceMonitor do Prometheus, mas voc√™ pode pegar o ServiceMonitor de qualquer outro servi√ßo.
```sh
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"monitoring.coreos.com/v1","kind":"ServiceMonitor","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"prometheus","app.kubernetes.io/instance":"k8s","app.kubernetes.io/name":"prometheus","app.kubernetes.io/part-of":"kube-prometheus","app.kubernetes.io/version":"2.41.0"},"name":"prometheus-k8s","namespace":"monitoring"},"spec":{"endpoints":[{"interval":"30s","port":"web"},{"interval":"30s","port":"reloader-web"}],"selector":{"matchLabels":{"app.kubernetes.io/component":"prometheus","app.kubernetes.io/instance":"k8s","app.kubernetes.io/name":"prometheus","app.kubernetes.io/part-of":"kube-prometheus"}}}}
  creationTimestamp: "2023-01-23T19:08:26Z"
  generation: 1
  labels:
    app.kubernetes.io/component: prometheus
    app.kubernetes.io/instance: k8s
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: kube-prometheus
    app.kubernetes.io/version: 2.41.0
  name: prometheus-k8s
  namespace: monitoring
  resourceVersion: "4100"
  uid: 6042e08c-cf18-4622-9860-3ff43e696f7c
spec:
  endpoints:
  - interval: 30s
    port: web
  - interval: 30s
    port: reloader-web
  selector:
    matchLabels:
      app.kubernetes.io/component: prometheus
      app.kubernetes.io/instance: k8s
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: kube-prometheus
Eu vou dar uma limpada nessa sa√≠da para ficar mais f√°cil de entender:

apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  annotations:
  labels:
    app.kubernetes.io/component: prometheus
    app.kubernetes.io/instance: k8s
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: kube-prometheus
    app.kubernetes.io/version: 2.41.0
  name: prometheus-k8s
  namespace: monitoring
spec:
  endpoints:
  - interval: 30s
    port: web
  - interval: 30s
    port: reloader-web
  selector:
    matchLabels:
      app.kubernetes.io/component: prometheus
      app.kubernetes.io/instance: k8s
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: kube-prometheus
```
Pronto, eu tirei algumas informa√ß√µes que n√£o s√£o importantes para a cria√ß√£o do ServiceMonitor, elas apenas trazer as informa√ß√µes do service monitor que foi criado e que pegamos a sa√≠da.

Com o arquivo limpo, podemos entender melhor o que est√° acontecendo.
```sh
apiVersion: Vers√£o da API do Kubernetes que estamos utilizando.
kind: Tipo de objeto que estamos criando.
metadata: Informa√ß√µes sobre o objeto que estamos criando.
metadata.annotations: Anota√ß√µes que podemos adicionar ao nosso objeto.
metadata.labels: Labels que podemos adicionar ao nosso objeto.
metadata.name: Nome do nosso objeto.
metadata.namespace: Namespace onde o nosso objeto ser√° criado.
spec: Especifica√ß√µes do nosso objeto.
spec.endpoints: Endpoints que o nosso ServiceMonitor ir√° monitorar.
spec.endpoints.interval: Intervalo de tempo que o Prometheus ir√° fazer a coleta de m√©tricas.
spec.endpoints.port: Porta que o Prometheus ir√° utilizar para coletar as m√©tricas.
spec.selector: Selector que o ServiceMonitor ir√° utilizar para encontrar os servi√ßos que ele ir√° monitorar.
```
Com isso, sabemos que o ServiceMonitor do Prometheus ir√° monitorar os servi√ßos que possuem as labels app.kubernetes.io/component: prometheus, app.kubernetes.io/instance: k8s, app.kubernetes.io/name: prometheus e app.kubernetes.io/part-of: kube-prometheus, e que ele ir√° monitorar as portas web e reloader-web com um intervalo de 30 segundos. √â f√°cil ou n√£o √©?

Ent√£o sempre que precisarmos criar um ServiceMonitor para monitorar algum servi√ßo, basta criarmos um arquivo YAML com as informa√ß√µes que precisamos e aplicarmos em nosso cluster.


Agora que j√° temos o nosso Kube-Prometheus instalado, vamos acessar o nosso Grafana e verificar se est√° tudo funcionando corretamente. Para isso, vamos utilizar o kubectl port-forward para acessar o Grafana localmente. Para isso, basta executar o seguinte comando:

kubectl port-forward -n monitoring svc/grafana 33000:3000
Agora que j√° temos o nosso Grafana rodando localmente, vamos acessar o nosso Grafana atrav√©s do navegador. Para isso, basta acessar a seguinte` URL: http://localhost:33000`

Para acessar o Grafana, vamos utilizar o usu√°rio admin e a senha admin, e j√° no primeiro login ele ir√° pedir para voc√™ alterar a senha. Voc√™ j√° conhece o Grafana, n√£o preciso mais apresenta-los, certo? üòÑ



O importante aqui √© ver a quantidade de Dashboards criados pelo` Kube-Prometheus`. üòÑ
Temos Dashboards que mostram detalhes do API Server e de diversos componentes do Kubernetes, como` Node`,` Pod,` `Deployment`, etc.



Tamb√©m temos Dashboards que mostram detalhes do nosso cluster EKS, como por exemplo o dashboard ``Kubernetes / Compute Resources / Cluster``, que mostra detalhes de `CPU` e mem√≥ria utilizados por todos os n√≥s do nosso cluster EKS.



Dashboards que mostram detalhes do nosso cluster EKS, como por exemplo o dashboard `Kubernetes / Compute Resources / Namespace (Pods)`, que mostra detalhes de CPU e mem√≥ria utilizados por todos os pods de todos os namespaces do nosso cluster EKS.



Ainda temos Dashboards que mostram detalhes do nosso cluster EKS, como por exemplo o dashboard` Kubernetes / Compute Resources / Namespace (Workloads)`, que mostra detalhes de CPU e mem√≥ria utilizados por todos os `deployments`, `statefulsets` e `daemonsets` de todos os` namespaces` do nosso cluster EKS.



Tamb√©m temos Dashboards que mostram detalhes do nosso cluster EKS, como por exemplo o dashboard` Kubernetes / Compute Resources / Node`, que mostra detalhes de CPU e mem√≥ria utilizados por todos os n√≥s do nosso cluster EKS.



Tamb√©m temos `Dashboards` que mostram detalhes do nosso cluster EKS, como por exemplo o dashboard `Kubernetes / Compute Resources / Pod (Containers)`, que mostra detalhes de CPU e mem√≥ria utilizados por todos os containers de todos os pods do nosso cluster EKS.



Eu n√£o vou ficar aqui dando spoilers, vai l√° voc√™ e confere a quantidade enorme de `Dashboards` que o` Kube-Prometheus` j√° vem com ele. \o/

Um dos principais recursos que o `Kube-Prometheus` utiliza √© o ServiceMonitor. O ServiceMonitor √© um recurso do Prometheus Operator que permite que voc√™ configure o Prometheus para monitorar um servi√ßo. Para isso, voc√™ precisa criar um ServiceMonitor para cada servi√ßo que voc√™ deseja monitorar.

O `Kube-Prometheus` j√° vem com v√°rios ServiceMonitors configurados, como por exemplo o ServiceMonitor do `API Server`, do `Node Exporter`, do `Blackbox Exporter`, etc.

```sh
kubectl get servicemonitors -n monitoring
```

```sh
NAME                      AGE
alertmanager              17m
blackbox-exporter         17m
coredns                   17m
grafana                   17m
kube-apiserver            17m
kube-controller-manager   17m
kube-scheduler            17m
kube-state-metrics        17m
kubelet                   17m
node-exporter             17m
prometheus-adapter        17m
prometheus-k8s            17m
prometheus-operator       17m
```


Para ver o conte√∫do de um ServiceMonitor, basta executar o seguinte comando:
```sh
kubectl get servicemonitor prometheus-k8s -n monitoring -o yaml
```
Nesse caso estamos pegando o ServiceMonitor do Prometheus, mas voc√™ pode pegar o ServiceMonitor de qualquer outro servi√ßo.

```sh
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"monitoring.coreos.com/v1","kind":"ServiceMonitor","metadata":{"annotations":{},"labels":{"app.kubernetes.io/component":"prometheus","app.kubernetes.io/instance":"k8s","app.kubernetes.io/name":"prometheus","app.kubernetes.io/part-of":"kube-prometheus","app.kubernetes.io/version":"2.41.0"},"name":"prometheus-k8s","namespace":"monitoring"},"spec":{"endpoints":[{"interval":"30s","port":"web"},{"interval":"30s","port":"reloader-web"}],"selector":{"matchLabels":{"app.kubernetes.io/component":"prometheus","app.kubernetes.io/instance":"k8s","app.kubernetes.io/name":"prometheus","app.kubernetes.io/part-of":"kube-prometheus"}}}}
  creationTimestamp: "2023-01-23T19:08:26Z"
  generation: 1
  labels:
    app.kubernetes.io/component: prometheus
    app.kubernetes.io/instance: k8s
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: kube-prometheus
    app.kubernetes.io/version: 2.41.0
  name: prometheus-k8s
  namespace: monitoring
  resourceVersion: "4100"
  uid: 6042e08c-cf18-4622-9860-3ff43e696f7c
spec:
  endpoints:
  - interval: 30s
    port: web
  - interval: 30s
    port: reloader-web
  selector:
    matchLabels:
      app.kubernetes.io/component: prometheus
      app.kubernetes.io/instance: k8s
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: kube-prometheus
Eu vou dar uma limpada nessa sa√≠da para ficar mais f√°cil de entender:

apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  annotations:
  labels:
    app.kubernetes.io/component: prometheus
    app.kubernetes.io/instance: k8s
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: kube-prometheus
    app.kubernetes.io/version: 2.41.0
  name: prometheus-k8s
  namespace: monitoring
spec:
  endpoints:
  - interval: 30s
    port: web
  - interval: 30s
    port: reloader-web
  selector:
    matchLabels:
      app.kubernetes.io/component: prometheus
      app.kubernetes.io/instance: k8s
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: kube-prometheus
```
Pronto, eu tirei algumas informa√ß√µes que n√£o s√£o importantes para a cria√ß√£o do ServiceMonitor, elas apenas trazer as informa√ß√µes do service monitor que foi criado e que pegamos a sa√≠da.

Com o arquivo limpo, podemos entender melhor o que est√° acontecendo.
```sh
apiVersion: Vers√£o da API do Kubernetes que estamos utilizando.
kind: Tipo de objeto que estamos criando.
metadata: Informa√ß√µes sobre o objeto que estamos criando.
metadata.annotations: Anota√ß√µes que podemos adicionar ao nosso objeto.
metadata.labels: Labels que podemos adicionar ao nosso objeto.
metadata.name: Nome do nosso objeto.
metadata.namespace: Namespace onde o nosso objeto ser√° criado.
spec: Especifica√ß√µes do nosso objeto.
spec.endpoints: Endpoints que o nosso ServiceMonitor ir√° monitorar.
spec.endpoints.interval: Intervalo de tempo que o Prometheus ir√° fazer a coleta de m√©tricas.
spec.endpoints.port: Porta que o Prometheus ir√° utilizar para coletar as m√©tricas.
spec.selector: Selector que o ServiceMonitor ir√° utilizar para encontrar os servi√ßos que ele ir√° monitorar.
```
Com isso, sabemos que o` ServiceMonitor` do` Prometheus` ir√° monitorar os servi√ßos que possuem as labels` app.kubernetes.io/component:` `prometheus, app.kubernetes.io/instance: k8s,`` app.kubernetes.io/name: prometheus` e `app.kubernetes.io/part-of: kube-prometheus,` e que ele ir√° monitorar as portas` web` e `reloader-web `com um intervalo de 30 segundos. √â f√°cil ou n√£o √©?

Ent√£o sempre que precisarmos criar um `ServiceMonitor` para monitorar algum servi√ßo, basta criarmos um arquivo `YAML` com as informa√ß√µes que precisamos e aplicarmos em nosso `cluster`.